<!doctype html>
<html lang="en">
  <head>
    <title>Python爬取笑话 // Whde</title>
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.55.6" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="Whde" />
    <meta name="description" content="Python爬取www.jokeji.cn笑话" />
    <link rel="stylesheet" href="https://whde.github.io/css/main.min.280093df0016aa5a8a32bd0943f5856c3372e631ca932fbaf43a52fdc26ab07c.css" />

    
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Python爬取笑话"/>
<meta name="twitter:description" content="Python爬取www.jokeji.cn笑话"/>

    <meta property="og:title" content="Python爬取笑话" />
<meta property="og:description" content="Python爬取www.jokeji.cn笑话" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://whde.github.io/posts/joke/" />
<meta property="article:published_time" content="2019-05-25T11:04:49&#43;08:00"/>
<meta property="article:modified_time" content="2019-05-25T11:04:49&#43;08:00"/>


  </head>
  <body>
    <header class="app-header">
      <a href="https://whde.github.io/"><img class="app-header-avatar" src="/avatar.jpg" alt="Whde" /></a>
      <h1>Whde</h1>
      <p>Same Mistakes</p>
      <div class="app-header-social">
        
          <a target="_blank" href="https://github.com/Whde"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-github">
  <title>github</title>
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path>
</svg></a>
        
      </div>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title">Python爬取笑话</h1>
      <div class="post-meta">
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          May 25, 2019
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          2 min read
        </div><div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tag">
  <title>tag</title>
  <path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line>
</svg>
          <a class="tag" href="https://whde.github.io/tags/python/">Python</a><a class="tag" href="https://whde.github.io/tags/mac/">Mac</a><a class="tag" href="https://whde.github.io/tags/%E7%AC%91%E8%AF%9D/">笑话</a><a class="tag" href="https://whde.github.io/tags/%E7%88%AC%E8%99%AB/">爬虫</a></div></div>
    </header>
    <div class="post-content">
      

<h3 id="python爬取笑话">Python爬取笑话</h3>

<p>Python爬取笑话排行，将数据以json存储到文件中</p>

<p>我们爬取的地址是：<a href="http://www.jokeji.cn/hot.asp?action=brow">http://www.jokeji.cn/hot.asp?action=brow</a></p>

<p>分析一下，我们需要爬取总页数，然后读取每页下面的笑话，笑话内容需要去详情页去爬取</p>

<h5 id="1-首先我们创建一个程序入口">1、首先我们创建一个程序入口</h5>

<ul>
<li>我们创建一个文件夹，文件夹里最后存数据文件进去</li>
<li>spider(root_url) 方法开始爬取数据，这个方法我们自己实现</li>
</ul>

<pre><code class="language-python"># 程序入口
if __name__ == &quot;__main__&quot;:
    # 创建文件夹，最后存数据到这个文件夹下面
    importlib.reload(sys)
    if os.path.isdir(root_folder):
        pass
    else:
        os.mkdir(root_folder)
    # 开始爬取数据
    spider(root_url)
    print('**** spider ****')
</code></pre>

<h5 id="2-开始爬取数据spider-root-url">2、开始爬取数据spider(root_url)</h5>

<ul>
<li>先去getpages(url)获取页数pages，后面会讲到</li>
<li>page(pageurl)获取每页里面数据</li>
<li>数据爬完，存储到data.json文件中</li>
</ul>

<pre><code class="language-python"># 开始爬取数据
def spider(url):
    list1 = []
    i = 1
    # 去获取排行榜的页数
    pages = getpages(url)
    while i &lt;= int(pages):
        # 拼接每一页的URL地址
        pageurl = 'http://www.jokeji.cn/hot.asp?action=brow&amp;me_page='+str(i)
        print(pageurl)
        # 获取每页下面的内容
        list1 = list1+page(pageurl)
        i = i+1
        pass
    else:
        print('大于页数')

    # 将list存储到data.json中
    try:
        filename = root_folder + 'data.json'
        with open(filename, &quot;wb&quot;) as f:
            stri = json.dumps(list1, encoding='UTF-8', ensure_ascii=False)
            print(stri)
            f.write(stri)
        pass
    except Exception as e:
        print('Error:', e)
        pass
    pass
</code></pre>

<h5 id="3-获取页数getpages-url">3、获取页数getpages(url)</h5>

<p>找最后一页的逻辑(如图)，最后一页在这个<code>&gt;&gt;</code>按钮里面，我们看源码，可以看到598，598就是总的页数了，接下来就是怎么获取这个页数。我们找到Class=&ldquo;main_title&rdquo;，然后找这main_title下面的所有td，我们所要的598就在倒数第二个td中，最后处理字符串，取出598。</p>

<p><img src="/images/WX20181205-164111@2x.png" alt="最后一页的逻辑" width=90% height=90%/></p>

<pre><code class="language-python"># 获取排行榜的页数
def getpages(url):
    print(url)
    url = quote(url, safe=string.printable)
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'
    }
    http = urllib3.PoolManager()
    web_data = http.request('GET', url, headers=headers).data
    # web_data = requests.get(url, headers=headers)
    # web_data.encoding = 'gb2312'
    soup = BeautifulSoup(web_data, 'html.parser', from_encoding='GBK')
    print(web_data)
    # 找总页数
    span = soup.find(class_='main_title')
    tds = span.findAll('td')
    td = tds[len(tds)-2]
    pages = td.select('a')[0].get('href').replace('hot.asp?action=brow&amp;me_page=', '')
    print(pages)
    return pages
</code></pre>

<h5 id="4-page-pageurl-获取每页里面数据">4、page(pageurl)获取每页里面数据</h5>

<p>getmeichannel(url)获取当前页下面的笑话列表</p>

<p>然后再detail(herf)去爬取每个笑话的详情</p>

<p>爬取逻辑看图：</p>

<p><img src="/images/WX20181205-174145@2x.png" alt="WX20181205-174145@2x.png" width=90% height=90%/></p>

<pre><code class="language-python"># 爬取每页下面的内容
def page(url):
    # 获取每页下面的笑话list
    channel_list = getmeichannel(url)
    list1 = []
    for tr in channel_list:
        dict1 = {}
        a = tr.find(class_='main_14')
        herf = 'http://www.jokeji.cn'+a.get('href')
        title = a.get_text()
        print(str(herf)+' --- '+str(title))
        dict1['herf'] = herf
        dict1['title'] = title
        dict1['date'] = tr.find(class_='date').get_text().replace('\r\n          ', '')
        # 获取当前笑话的详情，去详情页爬取数据
        dict1['detail'] = detail(herf)
        list1.append(dict1)
    return list1
</code></pre>

<h5 id="5-getmeichannel-url-获取当前页下面的笑话列表">5、getmeichannel(url)获取当前页下面的笑话列表</h5>

<pre><code class="language-python"># 获取排行榜URL页下面的笑话list数据
def getmeichannel(url):
    url = quote(url, safe=string.printable)
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'
    }
    http = urllib3.PoolManager()
    web_data = http.request('GET', url, headers=headers).data
    soup = BeautifulSoup(web_data, 'html.parser', from_encoding='GBK')
    channel = []
    tables = soup.findAll(height='30')
    for table in tables:
        try:
            for tr in table.findAll('tr'):
                channel.append(tr)
                pass
        except Exception as e:
            print('Error:', e)
            pass
    return channel
</code></pre>

<h5 id="6-获取详情数据detail-herf">6、获取详情数据detail(herf)</h5>

<pre><code class="language-python"># 爬取详情页数据
def detail(url):
    url = quote(url, safe=string.printable)
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'
    }
    http = urllib3.PoolManager()
    r = http.request('GET', url, headers=headers)
    web_data = r.data
    soup = BeautifulSoup(web_data, 'html.parser', from_encoding='GBK')
    # 查找详情页数据
    font = soup.find(attrs={'id': 'text110'})
    try:
        return font.get_text()
        pass
    except Exception as e:
        print(str(e))
        return ''
        pass
</code></pre>

<p>源码地址<a href="https://github.com/whde/Joke.git">https://github.com/whde/Joke.git</a></p>

    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>
  </body>
</html>
